import base64
import json
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from enum import Enum
from typing import Dict, List, Optional, Tuple
import requests

from .config import Config
from .constants import PROMPT_TEMPLATE, DEFAULT_BATCH_SIZE
from .logger import Logger


class APIErrorType(Enum):
    """APIé”™è¯¯ç±»å‹æšä¸¾"""
    SUCCESS = "success"
    AUTH_ERROR = "auth_error"          # APIå¯†é’¥é—®é¢˜ (401, 403)
    RATE_LIMIT = "rate_limit"          # å¹¶å‘é™åˆ¶ (429)
    CONCURRENCY_ERROR = "concurrency"  # å¹¶å‘ç›¸å…³é”™è¯¯
    SERVER_ERROR = "server_error"      # æœåŠ¡å™¨é”™è¯¯ (5xx)
    TIMEOUT = "timeout"                # è¶…æ—¶
    NETWORK_ERROR = "network_error"    # ç½‘ç»œé”™è¯¯
    UNKNOWN = "unknown"                # æœªçŸ¥é”™è¯¯


class BatchResult:
    """æ‰¹æ¬¡å¤„ç†ç»“æœ"""
    def __init__(self):
        self.results: Dict[str, str] = {}
        self.failed_paths: List[str] = []
        self.error_type: Optional[APIErrorType] = None
        self.should_fallback_sequential: bool = False
        self.api_completely_failed: bool = False


class VLMClient:
    def __init__(self, config: Config, logger: Logger):
        self.config = config
        self.logger = logger
        self._consecutive_failures = 0
        self._max_consecutive_failures = 3
        self._concurrency_failed = False
    
    def _encode_image(self, image_path: str) -> Optional[str]:
        try:
            with open(image_path, 'rb') as f:
                image_data = f.read()
                return base64.b64encode(image_data).decode('utf-8')
        except Exception as e:
            self.logger.log_error(image_path, f"Failed to read image: {e}")
            return None
    
    def _classify_error(self, error: Exception, response: Optional[requests.Response] = None) -> APIErrorType:
        """æ ¹æ®å¼‚å¸¸å’Œå“åº”åˆ†ç±»é”™è¯¯ç±»å‹"""
        if isinstance(error, requests.exceptions.Timeout):
            return APIErrorType.TIMEOUT
        
        if isinstance(error, requests.exceptions.ConnectionError):
            return APIErrorType.NETWORK_ERROR
        
        if response is not None:
            status_code = response.status_code
            if status_code in (401, 403):
                return APIErrorType.AUTH_ERROR
            elif status_code == 429:
                return APIErrorType.RATE_LIMIT
            elif status_code >= 500:
                return APIErrorType.SERVER_ERROR
        
        if isinstance(error, requests.exceptions.HTTPError):
            if hasattr(error, 'response') and error.response is not None:
                status_code = error.response.status_code
                if status_code in (401, 403):
                    return APIErrorType.AUTH_ERROR
                elif status_code == 429:
                    return APIErrorType.RATE_LIMIT
                elif status_code >= 500:
                    return APIErrorType.SERVER_ERROR
        
        # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯ä¸­çš„å¹¶å‘ç›¸å…³å…³é”®è¯
        error_msg = str(error).lower()
        concurrency_keywords = ['concurrent', 'rate limit', 'too many', 'throttl', 'quota']
        if any(kw in error_msg for kw in concurrency_keywords):
            return APIErrorType.CONCURRENCY_ERROR
        
        return APIErrorType.UNKNOWN
    
    def _call_api(self, image_path: str, base64_image: str) -> Tuple[Optional[str], APIErrorType]:
        """è°ƒç”¨APIï¼Œè¿”å›ç»“æœå’Œé”™è¯¯ç±»å‹"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.key}"
        }
        
        payload = {
            "model": self.config.model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": PROMPT_TEMPLATE
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 4096
        }
        
        last_error_type = APIErrorType.UNKNOWN
        
        for attempt in range(self.config.retries):
            response = None
            try:
                response = requests.post(
                    str(self.config.endpoint),
                    headers=headers,
                    json=payload,
                    timeout=self.config.timeout
                )
                
                response.raise_for_status()
                
                data = response.json()
                content = data['choices'][0]['message']['content']
                
                return content, APIErrorType.SUCCESS
            
            except requests.exceptions.Timeout as e:
                last_error_type = APIErrorType.TIMEOUT
                if attempt < self.config.retries - 1:
                    time.sleep(2 ** attempt)
                    continue
            
            except requests.exceptions.HTTPError as e:
                last_error_type = self._classify_error(e, response)
                if last_error_type == APIErrorType.AUTH_ERROR:
                    return None, last_error_type
                if last_error_type == APIErrorType.RATE_LIMIT:
                    if attempt < self.config.retries - 1:
                        time.sleep(5 * (attempt + 1))
                        continue
                if attempt < self.config.retries - 1:
                    time.sleep(2 ** attempt)
                    continue
            
            except requests.exceptions.RequestException as e:
                last_error_type = self._classify_error(e, response)
                if attempt < self.config.retries - 1:
                    time.sleep(2 ** attempt)
                    continue
            
            except Exception as e:
                last_error_type = self._classify_error(e, response)
                if attempt < self.config.retries - 1:
                    time.sleep(2 ** attempt)
                    continue
        
        return None, last_error_type
    
    def _parse_response(self, response_text: str) -> Optional[str]:
        pattern = r'```figure\n([\s\S]*?)\n```'
        match = re.search(pattern, response_text)
        
        if match:
            return match.group(1).strip()
        
        return response_text.strip() if response_text else None
    
    def describe_image(self, image_path: str) -> Tuple[Optional[str], APIErrorType]:
        """æè¿°å•å¼ å›¾ç‰‡ï¼Œè¿”å›æè¿°å’Œé”™è¯¯ç±»å‹"""
        base64_image = self._encode_image(image_path)
        
        if not base64_image:
            return None, APIErrorType.UNKNOWN
        
        try:
            response, error_type = self._call_api(image_path, base64_image)
            
            if response:
                return self._parse_response(response), APIErrorType.SUCCESS
            
            return None, error_type
        
        except Exception as e:
            self.logger.log_error(image_path, str(e))
            return None, self._classify_error(e)
    
    def _process_batch_concurrent(
        self, 
        batch_items: List[Tuple[str, str]]
    ) -> Tuple[Dict[str, str], List[Tuple[str, str, APIErrorType]]]:
        """å¹¶å‘å¤„ç†ä¸€æ‰¹å›¾ç‰‡"""
        results = {}
        failures = []
        
        with ThreadPoolExecutor(max_workers=min(len(batch_items), self.config.max_concurrency)) as executor:
            futures = {
                executor.submit(self.describe_image, full_path): (rel_path, full_path)
                for rel_path, full_path in batch_items
            }
            
            for future in as_completed(futures):
                rel_path, full_path = futures[future]
                
                try:
                    description, error_type = future.result()
                    
                    if description:
                        results[rel_path] = description
                    else:
                        failures.append((rel_path, full_path, error_type))
                
                except Exception as e:
                    error_type = self._classify_error(e)
                    failures.append((rel_path, full_path, error_type))
        
        return results, failures
    
    def _process_sequential(
        self, 
        items: List[Tuple[str, str]],
        progress_offset: int = 0,
        total: int = 0
    ) -> Tuple[Dict[str, str], List[Tuple[str, str, APIErrorType]]]:
        """é¡ºåºå¤„ç†å›¾ç‰‡ï¼ˆé™çº§æ¨¡å¼ï¼‰"""
        results = {}
        failures = []
        
        for i, (rel_path, full_path) in enumerate(items):
            current = progress_offset + i + 1
            
            description, error_type = self.describe_image(full_path)
            
            if description:
                results[rel_path] = description
                self.logger.log_progress(current, total or len(items), rel_path, True)
            else:
                failures.append((rel_path, full_path, error_type))
                self.logger.log_progress(current, total or len(items), rel_path, False)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                if error_type == APIErrorType.AUTH_ERROR:
                    print("\nâŒ APIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
                    return results, failures
        
        return results, failures
    
    def _should_fallback_to_sequential(self, failures: List[Tuple[str, str, APIErrorType]]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é™çº§åˆ°é¡ºåºå¤„ç†"""
        if not failures:
            return False
        
        error_types = [f[2] for f in failures]
        
        # å¦‚æœå¤§éƒ¨åˆ†æ˜¯é€Ÿç‡é™åˆ¶æˆ–å¹¶å‘é”™è¯¯ï¼Œåˆ™é™çº§
        concurrency_errors = sum(1 for e in error_types if e in (
            APIErrorType.RATE_LIMIT, 
            APIErrorType.CONCURRENCY_ERROR
        ))
        
        return concurrency_errors >= len(failures) * 0.5
    
    def _is_api_completely_failed(self, failures: List[Tuple[str, str, APIErrorType]]) -> bool:
        """åˆ¤æ–­APIæ˜¯å¦å®Œå…¨æ— æ³•ä½¿ç”¨"""
        if not failures:
            return False
        
        error_types = [f[2] for f in failures]
        
        # æ‰€æœ‰è¯·æ±‚éƒ½æ˜¯è®¤è¯é”™è¯¯
        auth_errors = sum(1 for e in error_types if e == APIErrorType.AUTH_ERROR)
        return auth_errors == len(failures)
    
    def describe_images_batch(
        self, 
        image_paths: Dict[str, str]
    ) -> BatchResult:
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡ï¼Œæ¯æ‰¹10å¼ 
        
        è¿”å›BatchResultåŒ…å«:
        - results: æˆåŠŸå¤„ç†çš„æè¿°
        - failed_paths: å¤„ç†å¤±è´¥çš„è·¯å¾„
        - should_fallback_sequential: æ˜¯å¦åº”é™çº§ä¸ºé¡ºåºå¤„ç†
        - api_completely_failed: APIæ˜¯å¦å®Œå…¨å¤±è´¥
        """
        batch_result = BatchResult()
        total = len(image_paths)
        
        if total == 0:
            return batch_result
        
        items = list(image_paths.items())
        batch_size = DEFAULT_BATCH_SIZE
        processed = 0
        
        # ç¬¬ä¸€æ‰¹å°è¯•å¹¶å‘
        first_batch = items[:min(batch_size, len(items))]
        print(f"\nğŸš€ å°è¯•å¹¶å‘å¤„ç† (æ‰¹æ¬¡å¤§å°: {len(first_batch)})")
        
        results, failures = self._process_batch_concurrent(first_batch)
        batch_result.results.update(results)
        processed += len(first_batch)
        
        # æ›´æ–°è¿›åº¦
        for rel_path in results:
            self.logger.log_progress(
                len(batch_result.results), 
                total, 
                rel_path, 
                True
            )
        
        # åˆ†æç¬¬ä¸€æ‰¹ç»“æœ
        if self._is_api_completely_failed(failures):
            print("\nâŒ APIå®Œå…¨æ— æ³•ä½¿ç”¨ï¼Œå°†è¾“å‡ºåŸå§‹MinerUç»“æœ")
            batch_result.api_completely_failed = True
            batch_result.failed_paths = [f[0] for f in failures]
            return batch_result
        
        if self._should_fallback_to_sequential(failures):
            print("\nâš ï¸ æ£€æµ‹åˆ°å¹¶å‘é™åˆ¶ï¼Œé™çº§ä¸ºé¡ºåºå¤„ç†æ¨¡å¼")
            batch_result.should_fallback_sequential = True
            
            # é‡è¯•å¤±è´¥çš„å›¾ç‰‡ï¼ˆé¡ºåºæ¨¡å¼ï¼‰
            retry_items = [(f[0], f[1]) for f in failures]
            retry_results, retry_failures = self._process_sequential(
                retry_items, 
                len(batch_result.results), 
                total
            )
            batch_result.results.update(retry_results)
            
            # å¤„ç†å‰©ä½™å›¾ç‰‡ï¼ˆé¡ºåºæ¨¡å¼ï¼‰
            remaining_items = items[processed:]
            if remaining_items:
                print(f"\nğŸ“ é¡ºåºå¤„ç†å‰©ä½™ {len(remaining_items)} å¼ å›¾ç‰‡")
                remaining_results, remaining_failures = self._process_sequential(
                    remaining_items,
                    len(batch_result.results),
                    total
                )
                batch_result.results.update(remaining_results)
                batch_result.failed_paths.extend([f[0] for f in remaining_failures])
            
            batch_result.failed_paths.extend([f[0] for f in retry_failures])
            return batch_result
        
        # å¤„ç†ç¬¬ä¸€æ‰¹çš„å¤±è´¥é¡¹
        if failures:
            # é‡è¯•å¤±è´¥çš„é¡¹
            retry_items = [(f[0], f[1]) for f in failures]
            retry_results, retry_failures = self._process_sequential(
                retry_items,
                len(batch_result.results),
                total
            )
            batch_result.results.update(retry_results)
            batch_result.failed_paths.extend([f[0] for f in retry_failures])
        
        # ç»§ç»­å¹¶å‘å¤„ç†å‰©ä½™æ‰¹æ¬¡
        while processed < len(items):
            batch_start = processed
            batch_end = min(processed + batch_size, len(items))
            batch_items = items[batch_start:batch_end]
            
            print(f"\nğŸš€ å¤„ç†æ‰¹æ¬¡ {batch_start // batch_size + 2} ({len(batch_items)} å¼ )")
            
            results, failures = self._process_batch_concurrent(batch_items)
            batch_result.results.update(results)
            processed = batch_end
            
            # æ›´æ–°è¿›åº¦
            for rel_path in results:
                self.logger.log_progress(
                    len(batch_result.results), 
                    total, 
                    rel_path, 
                    True
                )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é™çº§
            if self._should_fallback_to_sequential(failures):
                print("\nâš ï¸ æ£€æµ‹åˆ°å¹¶å‘é™åˆ¶ï¼Œé™çº§ä¸ºé¡ºåºå¤„ç†æ¨¡å¼")
                batch_result.should_fallback_sequential = True
                
                # é‡è¯•å¤±è´¥çš„
                retry_items = [(f[0], f[1]) for f in failures]
                retry_results, retry_failures = self._process_sequential(
                    retry_items,
                    len(batch_result.results),
                    total
                )
                batch_result.results.update(retry_results)
                
                # é¡ºåºå¤„ç†å‰©ä½™
                remaining_items = items[processed:]
                if remaining_items:
                    print(f"\nğŸ“ é¡ºåºå¤„ç†å‰©ä½™ {len(remaining_items)} å¼ å›¾ç‰‡")
                    remaining_results, remaining_failures = self._process_sequential(
                        remaining_items,
                        len(batch_result.results),
                        total
                    )
                    batch_result.results.update(remaining_results)
                    batch_result.failed_paths.extend([f[0] for f in remaining_failures])
                
                batch_result.failed_paths.extend([f[0] for f in retry_failures])
                break
            
            # é‡è¯•å¤±è´¥çš„é¡¹
            if failures:
                retry_items = [(f[0], f[1]) for f in failures]
                retry_results, retry_failures = self._process_sequential(
                    retry_items,
                    len(batch_result.results),
                    total
                )
                batch_result.results.update(retry_results)
                batch_result.failed_paths.extend([f[0] for f in retry_failures])
        
        return batch_result
    
    # ä¿æŒå‘åå…¼å®¹çš„ç®€å•æ¥å£
    def describe_images_batch_simple(
        self, 
        image_paths: Dict[str, str]
    ) -> Dict[str, str]:
        """ç®€å•çš„æ‰¹é‡å¤„ç†æ¥å£ï¼ˆå‘åå…¼å®¹ï¼‰"""
        result = self.describe_images_batch(image_paths)
        return result.results
